{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d46c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB,MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from skmultilearn.problem_transform import BinaryRelevance,ClassifierChain,LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "237af224",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv('./train.csv')\n",
    "traindf['abstract'] = traindf['abstract'].apply(lambda abstract: abstract.strip('[]').split(', '))\n",
    "traindf['title'] = traindf['title'].apply(lambda title: title.strip('[]').split(', '))\n",
    "traindf['authors'] = traindf['authors'].apply(lambda authors: authors.strip('[]').split(', '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0cc38b",
   "metadata": {},
   "source": [
    "Combine title and abstract into a string for each article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "176e1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['combined_text'] = (traindf.title+traindf.abstract).apply(lambda text: ' '.join(text))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759789c1",
   "metadata": {},
   "source": [
    "Target Labels: (101 labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5b96efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def targetLabels(authorData):\n",
    "    labels = np.zeros((len(authorData),101))\n",
    "    for i, article in enumerate(authorData):\n",
    "        prolific = False\n",
    "        for j, author in enumerate(article):\n",
    "            author = int(author)\n",
    "            if author < 100:\n",
    "                prolific = True\n",
    "                labels[i][author] = 1\n",
    "        if not prolific:\n",
    "            labels[i][100] = 1\n",
    "    return labels\n",
    "\n",
    "def createTargetColumns(traindf):\n",
    "    targets = targetLabels(traindf['authors'])\n",
    "    for label in range(101):\n",
    "        traindf[str(label)] = [targets[article, label] for article in range(traindf.shape[0])]\n",
    "    return traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd77d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels = targetLabels(traindf['authors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265a50de",
   "metadata": {},
   "source": [
    "Identifying prolific articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73e7dfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     3 ... 25778 25781 25788]\n"
     ]
    }
   ],
   "source": [
    "train_prolific_ids = np.array([article_id for article_id in range(trainLabels.shape[0]) \n",
    "                               if np.sum(trainLabels[article_id][:100]) > 0])\n",
    "print(train_prolific_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c88442a",
   "metadata": {},
   "source": [
    "Identifying non-prolific articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecd71e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    2     5     6 ... 25790 25791 25792]\n"
     ]
    }
   ],
   "source": [
    "train_nonprolific_ids = np.array([article_id for article_id in range(trainLabels.shape[0]) \n",
    "                               if np.sum(trainLabels[article_id][:100]) == 0])\n",
    "print(train_nonprolific_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b991c",
   "metadata": {},
   "source": [
    "Create training sample with 25% non-prolific articles: (includes all prolific articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "068424eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527\n"
     ]
    }
   ],
   "source": [
    "rnd = np.random.RandomState(10)\n",
    "\n",
    "nonprolific_prop = 0.17\n",
    "n_prolific = train_prolific_ids.shape[0]\n",
    "n_articles = traindf.shape[0]\n",
    "n_nonprolific_samples = math.floor(nonprolific_prop/(1-nonprolific_prop)*n_prolific)\n",
    "\n",
    "train_nonprolific_sample_ids = rnd.choice(train_nonprolific_ids, size = n_nonprolific_samples, replace = False)\n",
    "\n",
    "print(len(train_nonprolific_sample_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9a1c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sample_ids = np.concatenate((train_prolific_ids, train_nonprolific_sample_ids), axis=0)\n",
    "\n",
    "training_sample = traindf.iloc[training_sample_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae5fa36",
   "metadata": {},
   "source": [
    "Sample labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5678e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleLabels = targetLabels(training_sample['authors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae437684",
   "metadata": {},
   "source": [
    "Split data into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08a25608",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, testData, labelsTrain, labelsTest = train_test_split(training_sample, sampleLabels, \n",
    "                                                                        test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9827f3e2",
   "metadata": {},
   "source": [
    "Extracting coauthor and venue features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "497c9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coauthorsFeatures(authorData):\n",
    "    coauthors = np.zeros((len(authorData), 21246),dtype=np.int8)\n",
    "    for i, article in enumerate(authorData):\n",
    "        for j, author in enumerate(article):\n",
    "            try:\n",
    "                author = int(author)\n",
    "                if author > 99:\n",
    "                    coauthors[i][author] = 1\n",
    "            except:\n",
    "                pass\n",
    "    return coauthors\n",
    "\n",
    "def venueFeatures(venueData):\n",
    "    venues = np.zeros((len(venueData), 465), dtype=np.int8)\n",
    "    for i, venue in enumerate(venueData):\n",
    "        if not np.isnan(venue):\n",
    "            venues[i][int(venue)] = 1\n",
    "    return venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e737b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCoauthors = coauthorsFeatures(trainData['authors'])\n",
    "trainVenues = venueFeatures(trainData['venue'])\n",
    "\n",
    "testCoauthors = coauthorsFeatures(testData['authors'])\n",
    "testVenues = venueFeatures(testData['venue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a84d7",
   "metadata": {},
   "source": [
    "Implementing Tf-Idf and obtaining features for text in trainData articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24afe899",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "trainTextfeatures = tfidf.fit_transform(trainData['combined_text']).toarray()\n",
    "\n",
    "testTextfeatures = tfidf.transform(testData['combined_text']).toarray()\n",
    "\n",
    "train_abstract_len = np.zeros(len(trainData))\n",
    "test_abstract_len = np.zeros(len(testData))\n",
    "\n",
    "train_title_len = np.zeros(len(trainData))\n",
    "test_title_len = np.zeros(len(testData))\n",
    "\n",
    "train_combined = np.zeros(len(trainData))\n",
    "test_combined = np.zeros(len(testData))\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in trainData['abstract'].index:\n",
    "    train_abstract_len[count] = len(trainData['abstract'][i])\n",
    "    train_title_len[count] = len(trainData['title'][i])\n",
    "    train_combined[count] = (train_title_len[count] + train_abstract_len[count])\n",
    "    count += 1\n",
    "\n",
    "count = 0\n",
    "for i in testData['abstract'].index:\n",
    "    test_abstract_len[count] = len(testData['abstract'][i])\n",
    "    test_title_len[count] = len(testData['title'][i])\n",
    "    test_combined[count] = (test_title_len[count] + test_abstract_len[count])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efce49f4",
   "metadata": {},
   "source": [
    "Concatenate features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46231688",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeatures = np.concatenate((trainCoauthors, trainVenues, trainTextfeatures), axis=1)\n",
    "\n",
    "testFeatures = np.concatenate((testCoauthors, testVenues, testTextfeatures), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f6fe47",
   "metadata": {},
   "source": [
    "## Binary Relevance with Multinomial NB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e84b726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy:': 0.007120605251446373, 'f1_score': 0.008386321188084668}\n"
     ]
    }
   ],
   "source": [
    "model = BinaryRelevance(MultinomialNB())\n",
    "model.fit(trainFeatures,labelsTrain)\n",
    "test_preds = model.predict(testFeatures)\n",
    "acc = accuracy_score(labelsTest, test_preds)\n",
    "f1 = f1_score(labelsTest, test_preds, average=\"samples\")\n",
    "result = {\"accuracy:\": acc, \"f1_score\": f1}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75f42e",
   "metadata": {},
   "source": [
    "## Binary Relevance with Complement NB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ce6fd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy:': 0.027147307521139297, 'f1_score': 0.029005420305402724}\n"
     ]
    }
   ],
   "source": [
    "model = BinaryRelevance(ComplementNB())\n",
    "model.fit(trainFeatures,labelsTrain)\n",
    "test_preds = model.predict(testFeatures)\n",
    "acc = accuracy_score(labelsTest, test_preds)\n",
    "f1 = f1_score(labelsTest, test_preds, average=\"samples\")\n",
    "result = {\"accuracy:\": acc, \"f1_score\": f1}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe65f7e",
   "metadata": {},
   "source": [
    "## Classifier Chain with Multinomial NB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2828263c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy:': 0.057096903900281465, 'f1_score': 0.05768663718000267}\n"
     ]
    }
   ],
   "source": [
    "model = ClassifierChain(MultinomialNB())\n",
    "model.fit(trainFeatures,labelsTrain)\n",
    "test_preds = model.predict(testFeatures)\n",
    "acc = accuracy_score(labelsTest, test_preds)\n",
    "f1 = f1_score(labelsTest, test_preds, average=\"samples\")\n",
    "result = {\"accuracy:\": acc, \"f1_score\": f1}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b5aafa",
   "metadata": {},
   "source": [
    "## Classifier Chain with Complement NB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3ee6e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy:': 0.11137917169280258, 'f1_score': 0.11318126987608292}\n"
     ]
    }
   ],
   "source": [
    "model = ClassifierChain(ComplementNB())\n",
    "model.fit(trainFeatures,labelsTrain)\n",
    "test_preds = model.predict(testFeatures)\n",
    "acc = accuracy_score(labelsTest, test_preds)\n",
    "f1 = f1_score(labelsTest, test_preds, average=\"samples\")\n",
    "result = {\"accuracy:\": acc, \"f1_score\": f1}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a20700",
   "metadata": {},
   "source": [
    "## Label Powerset with Multinomial NB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a56ce220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy:': 0.24567752312022517, 'f1_score': 0.24567752312022517}\n"
     ]
    }
   ],
   "source": [
    "model = LabelPowerset(MultinomialNB())\n",
    "model.fit(trainFeatures,labelsTrain)\n",
    "test_preds = model.predict(testFeatures)\n",
    "acc = accuracy_score(labelsTest, test_preds)\n",
    "f1 = f1_score(labelsTest, test_preds, average=\"samples\")\n",
    "result = {\"accuracy:\": acc, \"f1_score\": f1}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c72b9e3",
   "metadata": {},
   "source": [
    "## Label Powerset with Complement NB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "889b90af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy:': 0.6328910333735425, 'f1_score': 0.6806479407203171}\n"
     ]
    }
   ],
   "source": [
    "model = LabelPowerset(ComplementNB())\n",
    "model.fit(trainFeatures,labelsTrain)\n",
    "test_preds = model.predict(testFeatures)\n",
    "acc = accuracy_score(labelsTest, test_preds)\n",
    "f1 = f1_score(labelsTest, test_preds, average=\"samples\")\n",
    "result = {\"accuracy:\": acc, \"f1_score\": f1}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dbafc8",
   "metadata": {},
   "source": [
    "## Predict test set using Label Powerset with Complement NB:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e0f3af",
   "metadata": {},
   "source": [
    "### Model using full training data sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b2f913",
   "metadata": {},
   "source": [
    "Features and Tf-Idf for training sample: (Sample labels were calculated earlier: 'sampleLabels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4f66b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "sampleTextfeatures = tfidf.fit_transform(training_sample['combined_text']).toarray()\n",
    "\n",
    "sampleCoauthors = coauthorsFeatures(training_sample['authors'])\n",
    "sampleVenues = venueFeatures(training_sample['venue'])\n",
    "\n",
    "abstract_len = np.zeros(len(training_sample))\n",
    "title_len = np.zeros(len(training_sample))\n",
    "count = 0\n",
    "\n",
    "for i in training_sample['abstract'].index:\n",
    "    abstract_len[count] = len(training_sample['abstract'][i])\n",
    "    title_len[count] = len(training_sample['title'][i])\n",
    "    count += 1\n",
    "\n",
    "abstract_len = pd.Categorical(abstract_len, categories=range(3000))\n",
    "title_len = pd.Categorical(title_len, categories=range(110))\n",
    "\n",
    "abstract_len = pd.get_dummies(abstract_len)\n",
    "title_len = pd.get_dummies(title_len)\n",
    "\n",
    "\n",
    "\n",
    "#sampleFeatures = np.concatenate((sampleCoauthors, sampleVenues, sampleTextfeatures,abstract_len,title_len), axis=1)\n",
    "sampleFeatures = np.concatenate((sampleCoauthors, sampleVenues, sampleTextfeatures), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da0ebb",
   "metadata": {},
   "source": [
    "Fitting model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b314ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=LinearSVC(), require_dense=[True, True])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullmodel = LabelPowerset(LinearSVC())\n",
    "\n",
    "fullmodel.fit(sampleFeatures,sampleLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fae4d2f",
   "metadata": {},
   "source": [
    "Training metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1707926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy:': 1.0, 'f1_score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "fullmodel_predictions = fullmodel.predict(sampleFeatures)\n",
    "acc = accuracy_score(sampleLabels, fullmodel_predictions)\n",
    "f1 = f1_score(sampleLabels, fullmodel_predictions, average=\"samples\")\n",
    "result = {\"accuracy:\": acc, \"f1_score\": f1}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0d4c16",
   "metadata": {},
   "source": [
    "Test Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1067a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('test.csv')\n",
    "testdf['abstract'] = testdf['abstract'].apply(lambda abstract: abstract.strip('[]').split(', '))\n",
    "testdf['title'] = testdf['title'].apply(lambda title: title.strip('[]').split(', '))\n",
    "testdf['coauthors'] = testdf['coauthors'].apply(lambda authors: authors.strip('[]').split(', '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c99178",
   "metadata": {},
   "source": [
    "Test Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "040166c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf['combined_text'] = (testdf.title+testdf.abstract).apply(lambda text: ' '.join(text))\n",
    "testTextfeatures = tfidf.transform(testdf['combined_text']).toarray()\n",
    "\n",
    "testCoauthors = coauthorsFeatures(testdf['coauthors'])\n",
    "testVenues = venueFeatures(testdf['venue'])\n",
    "\n",
    "test_abstract_len = np.zeros(len(testdf))\n",
    "test_title_len = np.zeros(len(testdf))\n",
    "\n",
    "for i in range(len(testdf)):\n",
    "    test_abstract_len[i] = len(testdf.loc[i]['abstract'])\n",
    "    test_title_len[i] = len(testdf.loc[i]['title'])\n",
    "\n",
    "    \n",
    "test_abstract_len = pd.Categorical(test_abstract_len, categories=range(3000))\n",
    "test_title_len = pd.Categorical(test_title_len, categories=range(110))\n",
    "\n",
    "test_abstract_len = pd.get_dummies(test_abstract_len)\n",
    "test_title_len = pd.get_dummies(test_title_len)\n",
    "\n",
    "#testFeatures = np.concatenate((testCoauthors, testVenues, testTextfeatures,test_abstract_len,test_title_len), axis=1)\n",
    "testFeatures = np.concatenate((testCoauthors, testVenues, testTextfeatures), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62e0891",
   "metadata": {},
   "source": [
    "## Test predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a735a01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = fullmodel.predict(testFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2da070",
   "metadata": {},
   "source": [
    "Create submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df4d8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubmission(predictions, testdf, filename):\n",
    "    predDf = pd.DataFrame(data={'Id': [i for i in testdf['identifier']], 'Predict': [None for _ in range(testdf.shape[0])]})\n",
    "    for i in range(testdf.shape[0]):\n",
    "        if predictions[i,100] == 1:\n",
    "            predDf['Predict'][i] = '-1'\n",
    "            continue\n",
    "        pred_str = ''\n",
    "        for j in range(100):\n",
    "            if predictions[i,j] == 1:\n",
    "                pred_str = ' '.join((pred_str, str(j))).strip()\n",
    "        if len(pred_str) == 0:\n",
    "            pred_str = '-1'\n",
    "        predDf['Predict'][i] = pred_str\n",
    "    predDf.to_csv(filename, sep=',', index=False)\n",
    "    print(f'Saved predictions to {filename}')\n",
    "    return predDf                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6f718f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/jps96fjj65zgy85ymqhl7hpc0000gn/T/ipykernel_51349/641596467.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predDf['Predict'][i] = pred_str\n",
      "/var/folders/sj/jps96fjj65zgy85ymqhl7hpc0000gn/T/ipykernel_51349/641596467.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predDf['Predict'][i] = '-1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to Submission_SGD.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id Predict\n",
       "0      0      92\n",
       "1      1      -1\n",
       "2      2      31\n",
       "3      3      23\n",
       "4      4      32\n",
       "..   ...     ...\n",
       "795  795      54\n",
       "796  796      97\n",
       "797  797      13\n",
       "798  798      71\n",
       "799  799      43\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createSubmission(test_predictions, testdf, 'Submission_LinearSVC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1437ef-31da-4f38-a2be-e3bbe122961b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbcf0f9-3122-42d5-ad2d-ca580f44365f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b3725-2fcb-4c3c-a047-321a8681f781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
